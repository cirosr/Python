{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP8EIBSBKzfmC/cVyNPePwZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HHvEtC2g8A6H"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup"]},{"cell_type":"code","source":["site_map = 'https://www.pngmart.com/sitemap.xml'"],"metadata":{"id":"ZM0w4Chx8F5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = requests.get(site_map)"],"metadata":{"id":"TLe3r_0e8Gvq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xml = response.text"],"metadata":{"id":"qBsaiCV68Gxq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["soup = BeautifulSoup(xml,'xml')"],"metadata":{"id":"Qivzus_O8G0S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["soup"],"metadata":{"id":"mGP7EJ1T8cBZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["site_maps = []\n","for loc in soup.find_all('loc'):\n","  url = loc.text\n","  if 'posts' in url:\n","    print(loc.text)\n","    site_maps.append(url)"],"metadata":{"id":"IFl0IkPF8G2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["site_map1 = site_maps[0]"],"metadata":{"id":"vChLmJCu8G5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = requests.get(site_map1)"],"metadata":{"id":"iuyK_Auf8G7q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["soup = BeautifulSoup(response.text,'xml')"],"metadata":{"id":"j3cFmlsb8G-C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["master_list = []\n","for loc in soup.find_all('loc'):\n","    url = loc.text\n","    if 'image' in url:\n","      master_list.append(url)\n","print(master_list)"],"metadata":{"id":"KTNImJE-8HAW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image_url in master_list[0:10]:\n","  print(image_url)\n","  response = requests.get(image_url)\n","  soup = BeautifulSoup(response.text, 'html.parser')\n","  png_url = soup.find('a',{'class':'download'})['href']\n","  image = requests.get(png_url)\n","  image_title = png_url.split('/')[-1]+'-'+image_url.split('/')[-1]\n","  with open(image_title, 'wb') as file:\n","    file.write(image.content)"],"metadata":{"id":"n_gJSrCF8PWD"},"execution_count":null,"outputs":[]}]}